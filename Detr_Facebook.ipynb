{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN3Jxb3u2m9ggooIoDQU4EU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Belal-AI/FSDAwaesf/blob/main/Detr_Facebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hZgEqptvnjUU"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from PIL import Image\n",
        "from torchvision.models import resnet50\n",
        "import torch\n",
        "import requests\n",
        "import torchvision.transforms as T\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DETR_demo(nn.Module):\n",
        "    def __init__(self, num_classes, n_heads=8, embedd_dim=256) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = resnet50()      # the backbone ifn the detre is the resnet50 and its output 2048 before the fc\n",
        "        del self.backbone.fc\n",
        "\n",
        "        self.conv = nn.Conv2d(2048, embedd_dim, 1)  ## to reduce the number of channels\n",
        "        self.object_quer=nn.Parameter(torch.rand(300,1,embedd_dim),requires_grad=True) ## position encoding for the encoder input\n",
        "\n",
        "        self.flatten=nn.Flatten(start_dim=2,end_dim=3) ##flat the input for transformer to mekr just 3 dims(len_Seq,batch,embeddings)\n",
        "\n",
        "        self.transformer=nn.Transformer(embedd_dim,n_heads,6,6)\n",
        "\n",
        "        self.bbx_layer=nn.Linear(embedd_dim,4)\n",
        "        self.classifier=nn.Linear(embedd_dim,num_classes+1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\" the process path\"\"\"\n",
        "        x = self.backbone.conv1(x)\n",
        "        x = self.backbone.bn1(x)\n",
        "        x = self.backbone.relu(x)\n",
        "        x = self.backbone.maxpool(x)\n",
        "\n",
        "        x = self.backbone.layer1(x)\n",
        "        x = self.backbone.layer2(x)\n",
        "        x = self.backbone.layer3(x)\n",
        "        x = self.backbone.layer4(x)\n",
        "\n",
        "        x=self.conv(x)\n",
        "\n",
        "        x=self.flatten(x)\n",
        "        print(x.permute(2,0,1).shape)\n",
        "        print(self.object_quer.shape)\n",
        "\n",
        "        trans=self.transformer(x.permute(2,0,1),self.object_quer)\n",
        "\n",
        "        bbx=self.bbx_layer(trans)\n",
        "\n",
        "        cls=self.classifier(trans)\n",
        "\n",
        "\n",
        "        #print(trans.shape)\n",
        "        return bbx,cls\n"
      ],
      "metadata": {
        "id": "gGKxd9sEnj2N"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
        "im = Image.open(requests.get(url, stream=True).raw)\n",
        "print(im.size)\n",
        "transform = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "im=transform(im).unsqueeze(0)\n",
        "im.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PO9YQ-Swo9uh",
        "outputId": "93e652b1-782e-412d-f312-8386014fc4f3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(640, 480)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 480, 640])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=DETR_demo(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TDsf3i-wNcj",
        "outputId": "c7a0ae63-304d-44ef-f63a-c47586d715f8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optmizer=torch.optim.AdamW(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "cTIjHPG7F8ZM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optmizer.zero_grad()\n",
        "bbx,cls=model.forward(im)\n",
        "loss_bbx=torchvision.ops.distance_box_iou(bbx[0],torch.tensor([100, 50, 200, 150]).unsqueeze(0))\n",
        "loss_cls=criterion(cls[0],torch.tensor([0]))+loss_bbx\n",
        "loss_cls.backward()\n",
        "optmizer.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNsWd3aZje0E",
        "outputId": "efb7abb7-710f-4c4d-d53f-30358df53e5b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([300, 1, 256])\n",
            "torch.Size([300, 1, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x9VPf1QtjpxJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}